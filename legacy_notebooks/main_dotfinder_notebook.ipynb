{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions ...\n",
    "import cooler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import poisson\n",
    "\n",
    "from cooltools.plotools import show_heatmap_wfeat, get_kernel\n",
    "\n",
    "from cooltools.loopify import diagonal_matrix_tiling, \\\n",
    "                              get_adjusted_expected_tile_some_nans, \\\n",
    "                              multiple_test_BH, \\\n",
    "                              clust_2D_pixels\n",
    "\n",
    "from bioframe import parse_humanized, parse_region_string\n",
    "# from scipy.ndimage import convolve\n",
    "# from scipy.linalg import toeplitz\n",
    "\n",
    "\n",
    "from cooltools.snipping import LazyToeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HiCCUPS results \n",
    "\n",
    "We will import some of the results generated by Tyler and Houda, in order to compare our \"dot\"-fidner with the HiCCUPS loops-finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy,\\\n",
    "                 deepcopy\n",
    "\n",
    "def rao_to_loopify(fname,chrom,bin_size,centroid=True,color='blue',marker_size=36):\n",
    "    dat = pd.read_table(fname)\n",
    "    if centroid:\n",
    "        ddd = copy(dat[(dat['chr1']==chrom)&(dat['chr2']==chrom)][['centroid1','centroid2']])\n",
    "        ddd = ddd.rename(columns={'centroid1':'row','centroid2':'col'})\n",
    "    else:\n",
    "        ddd = copy(dat[(dat['chr1']==chrom)&(dat['chr2']==chrom)][['x1','y1']])\n",
    "        ddd = ddd.rename(columns={'x1':'row','y1':'col'})\n",
    "    ddd = ddd/bin_size\n",
    "    ddd['color']=color\n",
    "    ddd['marker_size']=marker_size\n",
    "    # return\n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs for `call_loops_per_chrom`\n",
    "\n",
    "Prepare a nice cooler-file, chromosome of interest, expected in `pd.DataFrame` format, and for now, just a single `kernels=[kernel, ]` to perform peak-calling against locally-adjusted expected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin-type fixed\n",
      "bin-size 20000\n",
      "nchroms 25\n",
      "nbins 154795\n",
      "sum 1106009388\n",
      "nnz 510537257\n",
      "genome-assembly hg19\n",
      "metadata {}\n",
      "creation-date 2017-12-11T06:24:11.564370\n",
      "generated-by cooler-0.7.5\n",
      "format HDF5::Cooler\n",
      "format-version 2\n",
      "format-url https://github.com/mirnylab/cooler\n"
     ]
    }
   ],
   "source": [
    "# cname = './houda/Houda_Ctrl_DpnII_K562.20000.cool'\n",
    "# cname = './houda/Houda_Ctrl_DpnII_K562.10000.cool'\n",
    "cname = './anne-laure/PTB2539-NT.20000.cool'\n",
    "ename = cname.rstrip(\".cool\") + \".cis.expected\"\n",
    "the_c = cooler.Cooler(cname)\n",
    "for k,v in the_c.info.items():\n",
    "    print(k,v)\n",
    "\n",
    "#chromosome of interest\n",
    "chrom = \"chr17\"\n",
    "\n",
    "# # Run CLI expected when needed:\n",
    "# !cooltools compute_expected --contact-type cis --nproc 18 $cname > $ename\n",
    "cis_exp = pd.read_table(ename,index_col=[0,1])\n",
    "# # trans expected, just for the record:\n",
    "# !cooltools compute_expected --contact-type trans PTB2539-NT.200000.cool > PTB2539-NT.200000.trans.expected\n",
    "# trans_exp = pd.read_table(\"PTB2539-NT.200000.trans.expected\",index_col=[0,1])\n",
    "\n",
    "# assuming cooler, chrom and expected as input ...\n",
    "ice_v_name = \"weight\"\n",
    "exp_v_name = \"balanced.avg\"\n",
    "\n",
    "# HICCUPS results loading ...\n",
    "frao = \"../Rao_MboI_K562_merged_loops.txt\"\n",
    "fhouda = \"../houda_control_DpnII_K562_merged_loops.txt\"\n",
    "\n",
    "b = the_c.info['bin-size']\n",
    "# drao - are loops called by Tyler on Rao2014 data K562  \n",
    "drao = rao_to_loopify(frao,chrom=chrom,bin_size=b)\n",
    "# dhouda - are loops called by Tyler on Houda's data K562  \n",
    "dhouda = rao_to_loopify(fhouda,chrom=chrom,bin_size=b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donut mask\n",
    "\n",
    "let's create a donut shape mask for downstream analysis ...\n",
    "\n",
    "We're exploring 10KB Hi-C matrix in this example, but donut-mask parameters, probably must be different for 10kb, look up Rao et el. 2014.\n",
    "\n",
    "params are not the most efficient, perhaps ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAAD/CAYAAABCS0s6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b5c767908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = 3\n",
    "p = 1\n",
    "kernel = get_kernel(w,p,ktype='donut')\n",
    "\n",
    "# kernel/kernel.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## stick to diag tiling strategy\n",
    "\n",
    "## todo:\n",
    "\n",
    " - combine into 1 pipeline ...\n",
    "\n",
    "\n",
    "### Trying the loopify:\n",
    "\n",
    "Let's finally try to call peaks using loopify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import multiprocessing as mp\n",
    "# nproc = len(the_c.chromnames[:-1])\n",
    "# print(\"creating a Pool of {} workers!\".format(nproc))\n",
    "# p = mp.Pool(nproc)\n",
    "\n",
    "# p.map?\n",
    "\n",
    "#####################################\n",
    "#     this used to be outside of func ...\n",
    "#####################################\n",
    "b = the_c.binsize\n",
    "band_2Mb = 2e+6\n",
    "band_idx = int(band_2Mb/b)\n",
    "# w = 3\n",
    "nans_tolerated = 1\n",
    "tile_size = int(12e6/b)\n",
    "verbosity = False\n",
    "clust_radius=39000\n",
    "threshold_cluster = round(clust_radius/float(b))\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "\n",
    "# for every chri ...\n",
    "def func(chri):\n",
    "    #     #####################################\n",
    "    #     #     this used to be outside of func ...\n",
    "    #     #####################################\n",
    "    #     b = the_c.binsize\n",
    "    #     band_2Mb = 2e+6\n",
    "    #     band_idx = int(band_2Mb/b)\n",
    "    #     # w = 3\n",
    "    #     nans_tolerated = 1\n",
    "    #     tile_size = int(12e6/b)\n",
    "    #     verbosity = False\n",
    "    #     clust_radius=39000\n",
    "    #     threshold_cluster = round(clust_radius/float(b))\n",
    "    #     #####################################\n",
    "    #     #####################################\n",
    "    chr_start,chr_stop = the_c.extent(chri)\n",
    "    lazy_exp = LazyToeplitz(cis_exp.loc[chri][exp_v_name].values)\n",
    "    #################################################\n",
    "    # test the newest 'get_adjusted_expected_tile_some_nans'\n",
    "    # using diagonal chunking here ...\n",
    "    #################################################\n",
    "    res_df = pd.DataFrame([])\n",
    "    for tile in diagonal_matrix_tiling(chr_start, chr_stop, w, band = band_idx):\n",
    "        tilei = tile\n",
    "        tilej = tile\n",
    "        # let's keep i,j-part explicit here:\n",
    "        origin = (tilei[0], tilej[0])\n",
    "        # RAW observed matrix slice:\n",
    "        observed = the_c.matrix(balance=False)[slice(*tilei), slice(*tilej)]\n",
    "        # expected as a tile :\n",
    "        expected = lazy_exp[slice(*tilei), slice(*tilej)]\n",
    "        # slice of ice_weight :\n",
    "        ice_weight = the_c.bins()[slice(*tile)][ice_v_name].values\n",
    "        # that's the main working function from loopify:\n",
    "        res = get_adjusted_expected_tile_some_nans(origin = origin,\n",
    "                                                 observed = observed,\n",
    "                                                 expected = expected,\n",
    "                                                 bal_weight = ice_weight,\n",
    "                                                 kernels = {\"donut\":kernel,},\n",
    "                                                 verbose = verbosity)\n",
    "        # post-processing filters now reside outside of get_la_exp:\n",
    "        is_inside_band = (res[\"bin1_id\"]>(res[\"bin2_id\"]-band_idx))\n",
    "        # departure from the tests - count NaNs in donut, not footprint ...\n",
    "        does_comply_nans = (res[\"la_exp.\"+\"donut\"+\".nnans\"] < nans_tolerated)\n",
    "        # so, selecting inside band and nNaNs compliant results:\n",
    "        res_df = res_df.append(\n",
    "                    res[is_inside_band & does_comply_nans],\n",
    "                    ignore_index=True)\n",
    "    # drop dups and reset index:\n",
    "    res_df = res_df.drop_duplicates().reset_index(drop=True)\n",
    "    #\n",
    "    # move Poisson tests here :\n",
    "    res_df[\"la_exp.\"+\"donut\"+\".pval\"] = 1.0 - \\\n",
    "            poisson.cdf(res_df[\"obs.raw\"],\n",
    "                        res_df[\"la_exp.\"+\"donut\"+\".value\"])\n",
    "    # perform multiple-hypoth testing for each chri\n",
    "    alpha=0.02\n",
    "    res_df['rej_null'], _ = multiple_test_BH(\n",
    "                                    res_df[\"la_exp.\"+\"donut\"+\".pval\"],\n",
    "                                    alpha=alpha)\n",
    "    # \n",
    "    #\n",
    "    # \n",
    "    # Next step is clustering of the data:\n",
    "    # cluster em' using the threshold:\n",
    "    peaks_clust = clust_2D_pixels(\n",
    "                        res_df[res_df['rej_null']],\n",
    "                        threshold_cluster=threshold_cluster)\n",
    "    # and merge (index-wise) with the main DataFrame:\n",
    "    res_df =  res_df.merge(\n",
    "                    peaks_clust,\n",
    "                    how='left',\n",
    "                    left_index=True,\n",
    "                    right_index=True)\n",
    "    #\n",
    "    return res_df\n",
    "#     print(\"chrom {} processing is complete\".format(chri))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a Pool of 24 workers!\n",
      "matrix of size 4060X4060 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 40  Non-edge case size of each tile is 206X206\n",
      "matrix of size 5127X5127 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 51  Non-edge case size of each tile is 206X206matrix of size 9046X9046 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 90  Non-edge case size of each tile is 206X206matrix of size 7957X7957 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 79  Non-edge case size of each tile is 206X206matrix of size 7061X7061 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 70  Non-edge case size of each tile is 206X206matrix of size 8556X8556 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 85  Non-edge case size of each tile is 206X206matrix of size 5368X5368 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 53  Non-edge case size of each tile is 206X206matrix of size 5759X5759 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 57  Non-edge case size of each tile is 206X206matrix of size 9902X9902 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 99  Non-edge case size of each tile is 206X206matrix of size 7319X7319 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 73  Non-edge case size of each tile is 206X206matrix of size 6777X6777 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 67  Non-edge case size of each tile is 206X206matrix of size 9558X9558 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 95  Non-edge case size of each tile is 206X206matrix of size 6751X6751 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 67  Non-edge case size of each tile is 206X206matrix of size 4518X4518 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 45  Non-edge case size of each tile is 206X206matrix of size 6693X6693 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 66  Non-edge case size of each tile is 206X206\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "matrix of size 12463X12463 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 124  Non-edge case size of each tile is 206X206matrix of size 12160X12160 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 121  Non-edge case size of each tile is 206X206\n",
      "\n",
      "matrix of size 3904X3904 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 39  Non-edge case size of each tile is 206X206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix of size 2566X2566 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 25  Non-edge case size of each tile is 206X206matrix of size 2957X2957 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 29  Non-edge case size of each tile is 206X206matrix of size 3152X3152 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 31  Non-edge case size of each tile is 206X206matrix of size 7764X7764 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 77  Non-edge case size of each tile is 206X206matrix of size 2407X2407 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 24  Non-edge case size of each tile is 206X206matrix of size 2969X2969 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 29  Non-edge case size of each tile is 206X206\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n",
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0163 and 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering is completed:\n",
      "there are 313 clusters detected\n",
      "mean size 13.881789+/-6.197657\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0000 and 0.0000\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 140 clusters detected\n",
      "mean size 2.042857+/-1.638254\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 544 clusters detected\n",
      "mean size 2.755515+/-2.541018\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 694 clusters detected\n",
      "mean size 2.332853+/-2.086774\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 778 clusters detected\n",
      "mean size 2.763496+/-2.560949\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 784 clusters detected\n",
      "mean size 2.581633+/-2.200642\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 356 clusters detected\n",
      "mean size 2.078652+/-1.717227\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 1034 clusters detected\n",
      "mean size 2.801741+/-2.637396\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0003 and 0.0003\n",
      "Clustering is completed:\n",
      "there are 1239 clusters detected\n",
      "mean size 3.143664+/-2.959292\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0000 and 0.0000\n",
      "Clustering is completed:\n",
      "there are 953 clusters detected\n",
      "mean size 2.781742+/-2.477306\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 564 clusters detected\n",
      "mean size 1.991135+/-1.607251\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 829 clusters detected\n",
      "mean size 2.348613+/-2.096079\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1359 clusters detected\n",
      "mean size 2.660780+/-2.389981\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 1434 clusters detected\n",
      "mean size 2.533473+/-2.226206\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 1569 clusters detected\n",
      "mean size 2.692161+/-2.460952\n",
      "labels and centroids to be reported.\n",
      "Clustering is completed:\n",
      "there are 1576 clusters detected\n",
      "mean size 2.773477+/-2.540301\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1545 clusters detected\n",
      "mean size 2.602589+/-2.246607\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1689 clusters detected\n",
      "mean size 2.589698+/-2.282668\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1962 clusters detected\n",
      "mean size 2.604485+/-2.330173\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2095 clusters detected\n",
      "mean size 2.563246+/-2.310645\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1997 clusters detected\n",
      "mean size 2.457687+/-2.180360\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2253 clusters detected\n",
      "mean size 2.462494+/-2.203584\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 2779 clusters detected\n",
      "mean size 2.657071+/-2.354984\n",
      "labels and centroids to be reported.\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2568 clusters detected\n",
      "mean size 2.528427+/-2.306864\n",
      "labels and centroids to be reported.\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# import multiprocessing as mp\n",
    "nproc = len(the_c.chromnames[:-1])\n",
    "print(\"creating a Pool of {} workers!\".format(nproc))\n",
    "with mp.Pool(nproc) as p:\n",
    "    rrrr = p.map(func, list(the_c.chromnames[:-1]))\n",
    "    \n",
    "\n",
    "# # p.map?\n",
    "\n",
    "# # p.map?\n",
    "# p.close()\n",
    "\n",
    "# p.join()\n",
    "\n",
    "# # # %%time\n",
    "# # pixel_info_Pool = dict(\n",
    "# #                     zip(\n",
    "# #                         the_c.chromnames[:-1],\n",
    "# #                         p.map(func, the_c.chromnames[:-1])\n",
    "# #                         )\n",
    "# #                        )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CPU times: user 592 ms, sys: 1.34 s, total: 1.94 s\n",
    "Wall time: 18.2 s\n",
    "\n",
    "manually calculated 20 seconds ... -wall time it is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix of size 12463X12463 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 124  Non-edge case size of each tile is 206X206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venevs/miniconda3/lib/python3.6/site-packages/cooltools/loopify.py:651: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Ek_raw = np.multiply(E_raw, np.divide(KO, KE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 2779 clusters detected\n",
      "mean size 2.657071+/-2.354984\n",
      "labels and centroids to be reported.\n",
      "chrom chr1 processing is complete\n",
      "matrix of size 12160X12160 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 121  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2568 clusters detected\n",
      "mean size 2.528427+/-2.306864\n",
      "labels and centroids to be reported.\n",
      "chrom chr2 processing is complete\n",
      "matrix of size 9902X9902 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 99  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2253 clusters detected\n",
      "mean size 2.462494+/-2.203584\n",
      "labels and centroids to be reported.\n",
      "chrom chr3 processing is complete\n",
      "matrix of size 9558X9558 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 95  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1997 clusters detected\n",
      "mean size 2.457687+/-2.180360\n",
      "labels and centroids to be reported.\n",
      "chrom chr4 processing is complete\n",
      "matrix of size 9046X9046 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 90  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 2095 clusters detected\n",
      "mean size 2.563246+/-2.310645\n",
      "labels and centroids to be reported.\n",
      "chrom chr5 processing is complete\n",
      "matrix of size 8556X8556 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 85  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1962 clusters detected\n",
      "mean size 2.604485+/-2.330173\n",
      "labels and centroids to be reported.\n",
      "chrom chr6 processing is complete\n",
      "matrix of size 7957X7957 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 79  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1689 clusters detected\n",
      "mean size 2.589698+/-2.282668\n",
      "labels and centroids to be reported.\n",
      "chrom chr7 processing is complete\n",
      "matrix of size 7319X7319 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 73  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1545 clusters detected\n",
      "mean size 2.602589+/-2.246607\n",
      "labels and centroids to be reported.\n",
      "chrom chr8 processing is complete\n",
      "matrix of size 7061X7061 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 70  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 1359 clusters detected\n",
      "mean size 2.660780+/-2.389981\n",
      "labels and centroids to be reported.\n",
      "chrom chr9 processing is complete\n",
      "matrix of size 6777X6777 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 67  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 1434 clusters detected\n",
      "mean size 2.533473+/-2.226206\n",
      "labels and centroids to be reported.\n",
      "chrom chr10 processing is complete\n",
      "matrix of size 6751X6751 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 67  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 1576 clusters detected\n",
      "mean size 2.773477+/-2.540301\n",
      "labels and centroids to be reported.\n",
      "chrom chr11 processing is complete\n",
      "matrix of size 6693X6693 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 66  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 1569 clusters detected\n",
      "mean size 2.692161+/-2.460952\n",
      "labels and centroids to be reported.\n",
      "chrom chr12 processing is complete\n",
      "matrix of size 5759X5759 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 57  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 829 clusters detected\n",
      "mean size 2.348613+/-2.096079\n",
      "labels and centroids to be reported.\n",
      "chrom chr13 processing is complete\n",
      "matrix of size 5368X5368 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 53  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 953 clusters detected\n",
      "mean size 2.781742+/-2.477306\n",
      "labels and centroids to be reported.\n",
      "chrom chr14 processing is complete\n",
      "matrix of size 5127X5127 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 51  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0003 and 0.0003\n",
      "Clustering is completed:\n",
      "there are 1239 clusters detected\n",
      "mean size 3.143664+/-2.959292\n",
      "labels and centroids to be reported.\n",
      "chrom chr15 processing is complete\n",
      "matrix of size 4518X4518 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 45  Non-edge case size of each tile is 206X206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 356 clusters detected\n",
      "mean size 2.078652+/-1.717227\n",
      "labels and centroids to be reported.\n",
      "chrom chr16 processing is complete\n",
      "matrix of size 4060X4060 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 40  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 1034 clusters detected\n",
      "mean size 2.801741+/-2.637396\n",
      "labels and centroids to be reported.\n",
      "chrom chr17 processing is complete\n",
      "matrix of size 3904X3904 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 39  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0001 and 0.0001\n",
      "Clustering is completed:\n",
      "there are 784 clusters detected\n",
      "mean size 2.581633+/-2.200642\n",
      "labels and centroids to be reported.\n",
      "chrom chr18 processing is complete\n",
      "matrix of size 2957X2957 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 29  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 694 clusters detected\n",
      "mean size 2.332853+/-2.086774\n",
      "labels and centroids to be reported.\n",
      "chrom chr19 processing is complete\n",
      "matrix of size 3152X3152 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 31  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 778 clusters detected\n",
      "mean size 2.763496+/-2.560949\n",
      "labels and centroids to be reported.\n",
      "chrom chr20 processing is complete\n",
      "matrix of size 2407X2407 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 24  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0000 and 0.0000\n",
      "Clustering is completed:\n",
      "there are 140 clusters detected\n",
      "mean size 2.042857+/-1.638254\n",
      "labels and centroids to be reported.\n",
      "chrom chr21 processing is complete\n",
      "matrix of size 2566X2566 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 25  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0002 and 0.0002\n",
      "Clustering is completed:\n",
      "there are 544 clusters detected\n",
      "mean size 2.755515+/-2.541018\n",
      "labels and centroids to be reported.\n",
      "chrom chr22 processing is complete\n",
      "matrix of size 7764X7764 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 77  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0000 and 0.0000\n",
      "Clustering is completed:\n",
      "there are 564 clusters detected\n",
      "mean size 1.991135+/-1.607251\n",
      "labels and centroids to be reported.\n",
      "chrom chrX processing is complete\n",
      "matrix of size 2969X2969 to be splitted so that\n",
      "  diagonal region of size 100 would be completely\n",
      "  covered by the tiling, additionally keeping\n",
      "  a small 'edge' of size w=3, to allow for\n",
      "  meaningfull convolution around boundaries.\n",
      "  Resulting number of tiles is 29  Non-edge case size of each tile is 206X206\n",
      "Some significant peaks have been detected!\n",
      "pval border is between 0.0163 and 0.0197\n",
      "Clustering is completed:\n",
      "there are 313 clusters detected\n",
      "mean size 13.881789+/-6.197657\n",
      "labels and centroids to be reported.\n",
      "chrom chrY processing is complete\n",
      "CPU times: user 3min 39s, sys: 3min 23s, total: 7min 3s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "b = the_c.binsize\n",
    "band_2Mb = 2e+6\n",
    "band_idx = int(band_2Mb/b)\n",
    "# w = 3\n",
    "nans_tolerated = 1\n",
    "tile_size = int(12e6/b)\n",
    "verbosity = False\n",
    "clust_radius=39000\n",
    "threshold_cluster = round(clust_radius/float(b))\n",
    "\n",
    "pixel_info = {}\n",
    "for chri in the_c.chromnames[:-1]:\n",
    "    chr_start,chr_stop = the_c.extent(chri)\n",
    "    lazy_exp = LazyToeplitz(cis_exp.loc[chri][exp_v_name].values)\n",
    "\n",
    "    #################################################\n",
    "    # test the newest 'get_adjusted_expected_tile_some_nans'\n",
    "    # using diagonal chunking here ...\n",
    "    #################################################\n",
    "    res_df = pd.DataFrame([])\n",
    "    for tile in diagonal_matrix_tiling(chr_start, chr_stop, w, band = band_idx):\n",
    "        tilei = tile\n",
    "        tilej = tile\n",
    "        # let's keep i,j-part explicit here:\n",
    "        origin = (tilei[0], tilej[0])\n",
    "        # RAW observed matrix slice:\n",
    "        observed = the_c.matrix(balance=False)[slice(*tilei), slice(*tilej)]\n",
    "        # expected as a tile :\n",
    "        expected = lazy_exp[slice(*tilei), slice(*tilej)]\n",
    "        # slice of ice_weight :\n",
    "        ice_weight = the_c.bins()[slice(*tile)][ice_v_name].values\n",
    "        # that's the main working function from loopify:\n",
    "        res = get_adjusted_expected_tile_some_nans(origin = origin,\n",
    "                                                 observed = observed,\n",
    "                                                 expected = expected,\n",
    "                                                 bal_weight = ice_weight,\n",
    "                                                 kernels = {\"donut\":kernel,},\n",
    "                                                 verbose = verbosity)\n",
    "        # post-processing filters now reside outside of get_la_exp:\n",
    "        is_inside_band = (res[\"bin1_id\"]>(res[\"bin2_id\"]-band_idx))\n",
    "        # departure from the tests - count NaNs in donut, not footprint ...\n",
    "        does_comply_nans = (res[\"la_exp.\"+\"donut\"+\".nnans\"] < nans_tolerated)\n",
    "        # so, selecting inside band and nNaNs compliant results:\n",
    "        res_df = res_df.append(\n",
    "                    res[is_inside_band & does_comply_nans],\n",
    "                    ignore_index=True)\n",
    "    # drop dups and reset index:\n",
    "    res_df = res_df.drop_duplicates().reset_index(drop=True)\n",
    "    #\n",
    "    # move Poisson tests here :\n",
    "    res_df[\"la_exp.\"+\"donut\"+\".pval\"] = 1.0 - \\\n",
    "            poisson.cdf(res_df[\"obs.raw\"],\n",
    "                        res_df[\"la_exp.\"+\"donut\"+\".value\"])\n",
    "    # adjust the origin :\n",
    "    # res_df['row'] = res_df['row'] - chr_start\n",
    "    # res_df['col'] = res_df['col'] - chr_start\n",
    "    #     \n",
    "    # perform multiple-hypoth testing for each chri\n",
    "    # right on spot:\n",
    "    # PER CHROM ACTION(? check Rao et al):\n",
    "    # cannot do it on kernel level, as it\n",
    "    # is tiled at that point ...\n",
    "    alpha=0.02\n",
    "    # alpaha could vary for different kernels ...\n",
    "    # alpha=0.1\n",
    "    res_df['rej_null'], _ = multiple_test_BH(\n",
    "                                    res_df[\"la_exp.\"+\"donut\"+\".pval\"],\n",
    "                                    alpha=alpha)\n",
    "    # \n",
    "    #\n",
    "    # \n",
    "    # Next step is clustering of the data:\n",
    "    ###############\n",
    "    # clustering starts here:\n",
    "    # http://scikit-learn.org/stable/modules/clustering.html\n",
    "    # picked Birch, as the most appropriate here:\n",
    "    ###############\n",
    "    # cluster em' using the threshold:\n",
    "    peaks_clust = clust_2D_pixels(\n",
    "                        res_df[res_df['rej_null']],\n",
    "                        threshold_cluster=threshold_cluster)\n",
    "    # and merge (index-wise) with the main DataFrame:\n",
    "    res_df =  res_df.merge(\n",
    "                    peaks_clust,\n",
    "                    how='left',\n",
    "                    left_index=True,\n",
    "                    right_index=True)\n",
    "    #\n",
    "    #\n",
    "    # save using a distinct name:\n",
    "    pixel_info[chri] = res_df\n",
    "    #\n",
    "    print(\"chrom {} processing is complete\".format(chri))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CPU times: user 3min 39s, sys: 3min 23s, total: 7min 3s\n",
    "Wall time: 2min 56s\n",
    "    \n",
    "manual: 2:57 !!! wall time it is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    " - replace pixel_info dict with a huge DataFrame\n",
    " - perform cooler.annotate on the entire pixel_info DataFrame (BEDPE-like) ...\n",
    " - see, if stuff like that should be done with filtering [rej_null] ?!(5kb will be scary ...)\n",
    " - come up with plotting tools that understand BEDPE - i.e. chrom, start, end - stuff\n",
    " - update other notebook ...\n",
    " - metric of pixel closeness in a BEDPE format - i.e. chrom, start, end (lookup in HiPiler) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start filtering out peaks DataFrame and deal with p-values\n",
    "\n",
    "### todo:\n",
    " - update the `get_adjusted_expected_tile_some_nans` interface, i.e. what's the output? which columns to include? etc.?\n",
    " - any extra filtering steps, depending on the output of the `get_adjusted_expected_tile_some_nans`?\n",
    " - upper triangle decision ?! do `get_adjusted_expected_tile_some_nans` return upper triangle contacts only? or full thing?\n",
    " - `NaN_mask` to be used as a mask or should we return `number_of_nans` for each pixel's vicinity ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dots to compare ...\n",
    "dots = pd.concat(( pixel_info[chri][pixel_info[chri]['rej_null']] for chri in the_c.chromnames[:-1] ))\n",
    "dots_Pool = pd.concat(( rrr[rrr['rej_null']] for rrr,chri in zip(rrrr,the_c.chromnames[:-1]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin1_id               True\n",
       "bin2_id               True\n",
       "la_exp.donut.value    True\n",
       "la_exp.donut.nnans    True\n",
       "exp.raw               True\n",
       "obs.raw               True\n",
       "la_exp.donut.pval     True\n",
       "rej_null              True\n",
       "cbin1_id              True\n",
       "cbin2_id              True\n",
       "c_label               True\n",
       "c_size                True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dots == dots_Pool).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin1_id</th>\n",
       "      <th>bin2_id</th>\n",
       "      <th>la_exp.donut.value</th>\n",
       "      <th>la_exp.donut.nnans</th>\n",
       "      <th>exp.raw</th>\n",
       "      <th>obs.raw</th>\n",
       "      <th>la_exp.donut.pval</th>\n",
       "      <th>rej_null</th>\n",
       "      <th>cbin1_id</th>\n",
       "      <th>cbin2_id</th>\n",
       "      <th>c_label</th>\n",
       "      <th>c_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>43</td>\n",
       "      <td>62</td>\n",
       "      <td>88.132672</td>\n",
       "      <td>0</td>\n",
       "      <td>44.019438</td>\n",
       "      <td>125</td>\n",
       "      <td>8.622993e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>45.076923</td>\n",
       "      <td>61.615385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>43</td>\n",
       "      <td>63</td>\n",
       "      <td>67.370764</td>\n",
       "      <td>0</td>\n",
       "      <td>34.489341</td>\n",
       "      <td>108</td>\n",
       "      <td>1.940658e-06</td>\n",
       "      <td>True</td>\n",
       "      <td>45.076923</td>\n",
       "      <td>61.615385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>65.258294</td>\n",
       "      <td>0</td>\n",
       "      <td>31.521203</td>\n",
       "      <td>113</td>\n",
       "      <td>3.017919e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>45.076923</td>\n",
       "      <td>61.615385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "      <td>105.092662</td>\n",
       "      <td>0</td>\n",
       "      <td>51.836615</td>\n",
       "      <td>184</td>\n",
       "      <td>1.237010e-12</td>\n",
       "      <td>True</td>\n",
       "      <td>45.076923</td>\n",
       "      <td>61.615385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>44</td>\n",
       "      <td>63</td>\n",
       "      <td>81.000719</td>\n",
       "      <td>0</td>\n",
       "      <td>40.452571</td>\n",
       "      <td>128</td>\n",
       "      <td>5.440388e-07</td>\n",
       "      <td>True</td>\n",
       "      <td>45.076923</td>\n",
       "      <td>61.615385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bin1_id  bin2_id  la_exp.donut.value  la_exp.donut.nnans    exp.raw  \\\n",
       "165       43       62           88.132672                   0  44.019438   \n",
       "166       43       63           67.370764                   0  34.489341   \n",
       "240       44       61           65.258294                   0  31.521203   \n",
       "241       44       62          105.092662                   0  51.836615   \n",
       "242       44       63           81.000719                   0  40.452571   \n",
       "\n",
       "     obs.raw  la_exp.donut.pval  rej_null   cbin1_id   cbin2_id  c_label  \\\n",
       "165      125       8.622993e-05      True  45.076923  61.615385      0.0   \n",
       "166      108       1.940658e-06      True  45.076923  61.615385      0.0   \n",
       "240      113       3.017919e-08      True  45.076923  61.615385      0.0   \n",
       "241      184       1.237010e-12      True  45.076923  61.615385      0.0   \n",
       "242      128       5.440388e-07      True  45.076923  61.615385      0.0   \n",
       "\n",
       "     c_size  \n",
       "165    11.0  \n",
       "166    11.0  \n",
       "240    11.0  \n",
       "241    11.0  \n",
       "242    11.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dots_Pool.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's try to annotate an entire dictionary 'pixel_info',\n",
    "# every pixel that was accepted ...\n",
    "dots = pd.concat((\n",
    "        cooler.annotate(\n",
    "            pixel_info[chri][pixel_info[chri]['rej_null']],\n",
    "            the_c.bins()[:]) \\\n",
    "        for chri in the_c.chromnames[:-1]\n",
    "        )) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots[['chrom1','start1','end1','chrom2','start2','end2','c_size']].to_csv(\n",
    "                                                                    \"PTB2539-NT.dots.bedpe.gz\",\n",
    "                                                                    sep='\\t',\n",
    "                                                                    header=False,\n",
    "                                                                    index=False,\n",
    "                                                                    compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrom = \"chr17\"\n",
    "peaks_local = pixel_info[chrom]\n",
    "M_ice = the_c.matrix().fetch(chrom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cooler.annotate?\n",
    "# cooler.annotate(pixels, bins, replace=True)\n",
    "#     A data frame containing columns named ``bin1_id`` and/or ``bin2_id``.\n",
    "#     If columns ``bin1_id`` and ``bin2_id`` are both present in ``pixels``,\n",
    "#     the adjoined columns will be suffixed with '1' and '2' accordingly.\n",
    "    \n",
    "cooler.annotate( peaks_local.rename(columns={\"row\":\"bin1_id\",\"col\":\"bin2_id\"}), the_c.bins()[:] ).head()\n",
    "\n",
    "\n",
    "# peaks_local.rename(mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total # of non-singleton peaks called :\n",
    "len(peaks_local[peaks_local['rej_null']&(peaks_local['c_size']>1)]['c_label'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to color some pixels \n",
    "# new_peaks[new_peaks['rej_null']]\n",
    "\n",
    "peaks_local['color'] = peaks_local['c_size'].apply(lambda x: 'blue' if x>1 else 'skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test the functions from plotools.py:\n",
    "\n",
    "# regions of interest\n",
    "# looprich in HEP and loop-poor in K562\n",
    "# \"chr17:8,000,000-14,000,000\"\n",
    "# looprich in K562 and loop-poor in HEP\n",
    "# \"chr17:46,000,000-50,000,000\"\n",
    "\n",
    "# \"chr8:101,000,000-104,000,000\"\n",
    "\n",
    "region_of_interest = \"chr17:8,000,000-14,000,000\"\n",
    "\n",
    "\n",
    "h_range = [int(_/b)\n",
    "             for _ in parse_region_string(region_of_interest)\n",
    "               if isinstance(_,int)]\n",
    "v_range = h_range\n",
    "\n",
    "# # mmm = combine_matrix_tris(M_ice, np.multiply(E_raw, np.outer(v_ice,v_ice)))\n",
    "ax = show_heatmap_wfeat(np.log10(M_ice),\n",
    "                   h_range,\n",
    "                   v_range,\n",
    "                   feature_df=peaks_local[peaks_local['rej_null']],\n",
    "                   b=b,\n",
    "                   show_bad=True,\n",
    "                   figsize=(22, 22),\n",
    "                   ax=None,\n",
    "                   bad_color='white',\n",
    "                   vmin=None,\n",
    "                   vmax=None,\n",
    "                   heat_type='log10')\n",
    "\n",
    "\n",
    "\n",
    "# ax.plot(\n",
    "#     [parse_humanized('8.0M'),parse_humanized('10.52M')],\n",
    "#     [parse_humanized('10.52M'),parse_humanized('10.52M')])\n",
    "\n",
    "\n",
    "# ax.plot(\n",
    "#     [parse_humanized('9.32M'),parse_humanized('10.52M')],\n",
    "#     [parse_humanized('10.52M'),parse_humanized('10.52M')],color='green',lw=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_heatmap_wfeat(np.log10(M_ice),\n",
    "                   h_range,\n",
    "                   v_range,\n",
    "                   feature_df=drao,\n",
    "                   b=b,\n",
    "                   show_bad=True,\n",
    "                   figsize=(22, 22),\n",
    "                   ax=None,\n",
    "                   bad_color='white',\n",
    "                   vmin=None,\n",
    "                   vmax=None,\n",
    "                   heat_type='log10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vicinity of a pixel\n",
    "\n",
    "simply plot a small vicinity of the pixel as a heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bioframe.parse_humanized('102.345M'))\n",
    "\n",
    "# # # peak pixel:\n",
    "# col = 491\n",
    "# row = 525\n",
    "\n",
    "\n",
    "# col,row = drao[(drao['row']*b/1000000>101.6)&(drao['row']*b/1000000<104)][['row','col']].iloc[2]\n",
    "\n",
    "# print(col*b/1000000)\n",
    "# print(row*b/1000000)\n",
    "\n",
    "# # col = 538\n",
    "# # row = 592\n",
    "\n",
    "# # vmin = -4.26018010407\n",
    "# # vmax = -0.900413109695\n",
    "\n",
    "# # h_range = (400,720)\n",
    "# # v_range = (400,720)\n",
    "\n",
    "# # h_range = (435,480)\n",
    "# # v_range = (435,480)\n",
    "\n",
    "# # h_range=(2260,2520)\n",
    "# # v_range=(2260,2520)\n",
    "\n",
    "\n",
    "\n",
    "# show_heatmap_pixel(np.log10(M_ice),\n",
    "#                    col=int(col),\n",
    "#                    row=int(row),\n",
    "#                    win=5,\n",
    "#                    ax=None,\n",
    "#                    vmin=None,\n",
    "#                    vmax=None,\n",
    "#                    ax_visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############\n",
    "# # next, we should check if\n",
    "# # using peaks_df['pval'] with NaNs\n",
    "# # and etc. yields the same results\n",
    "# # as excluding NaNs etc from array ...\n",
    "# ############\n",
    "# if peaks['pval'].isnull().any():\n",
    "#     print(\"There are NaNs among pvals ... #SAD\")\n",
    "    \n",
    "# # for fun ...\n",
    "# _,bins,_ = plt.hist(peaks['pval'],\n",
    "#                     log=True,\n",
    "#                     bins=np.logspace(-9,0,50),\n",
    "#                     label=\"all\")   \n",
    "# ax = plt.gca()\n",
    "# ###############\n",
    "# # do multiple-hyp-testing\n",
    "# ###############\n",
    "# rejnull, pvr = loopify.multiple_test_BH(peaks['pval'], alpha=0.02)\n",
    "\n",
    "# print(\"percent of Null hypothesis rejected {}\".format(rejnull.sum()/rejnull.size*100.0))\n",
    "\n",
    "# ############\n",
    "# # show pvals with Null rejected ...\n",
    "# ############\n",
    "# ax.hist(peaks[rejnull]['pval'],\n",
    "#         log=True,\n",
    "#         bins=bins,\n",
    "#         color='red',\n",
    "#         label=\"not_null\")\n",
    "\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_xlabel(\"p-value\")\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # peak pixel:\n",
    "# # 491,\n",
    "# # 525,\n",
    "\n",
    "# 538,\n",
    "# 592,\n",
    "\n",
    "\n",
    "\n",
    "pos = int(parse_humanized('10.52M')/b)\n",
    "\n",
    "dpos = int(parse_humanized('1.5M')/b)\n",
    "\n",
    "plt.plot(np.log10(M_ice[pos:pos+dpos,pos]),label=\"OBS\",lw=2)\n",
    "\n",
    "\n",
    "k = np.array([1,1,1,1,0,1,1,1,1])\n",
    "ccc = np.convolve(M_ice[pos:pos+dpos,pos],k/k.sum(),mode='same')\n",
    "cex = np.convolve(E_ice[pos:pos+dpos,pos],k/k.sum(),mode='same')\n",
    "\n",
    "plt.plot(np.log10(ccc[:dpos]),label=\"LOC\",lw=5)\n",
    "# plt.plot(np.log10(E_ice[pos:pos+dpos,pos]*ccc[:dpos]/cex[:dpos]))\n",
    "\n",
    "# plt.plot(np.log10(cex[:100]))\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# plt.plot(np.log10(E_ice[pos:pos+dpos,pos]),lw=5,label=\"EXP\")\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "f = plt.gcf()\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x,pos: x*b/1000000))\n",
    "ax.set_xlabel(\"distance from diagonal, M\",fontsize=16)\n",
    "ax.set_ylabel(\"log10(relative contact frequency)\",fontsize=16)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(14) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(14) \n",
    "\n",
    "# print(ax.get_xlim())\n",
    "# print(ax.get_ylim())\n",
    "\n",
    "ax.set_xlim((-3.7000000000000002, 77.700000000000003))\n",
    "ax.set_ylim((-3.1352748720026811, -1.1114994123986353))\n",
    "\n",
    "f.set_size_inches(14,10)\n",
    "\n",
    "#plt.plot(np.log10(M_ice[500,500:500+100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
